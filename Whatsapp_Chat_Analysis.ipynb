{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vendmfktfim",
        "outputId": "1ea6bcf5-aa5d-4637-b9d4-0ec2912ba7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "import regex\n",
        "!pip install emoji\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "import emoji\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def date_time(s):\n",
        "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "    result = regex.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def find_author(s):\n",
        "    s = s.split(\":\")\n",
        "    if len(s)==2:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def getDatapoint(line):\n",
        "    splitline = line.split(' - ')\n",
        "    dateTime = splitline[0]\n",
        "    date, time = dateTime.split(\", \")\n",
        "    message = \" \".join(splitline[1:])\n",
        "    if find_author(message):\n",
        "        splitmessage = message.split(\": \")\n",
        "        author = splitmessage[0]\n",
        "        message = \" \".join(splitmessage[1:])\n",
        "    else:\n",
        "        author= None\n",
        "    return date, time, author, message"
      ],
      "metadata": {
        "id": "4-I5Kc03txRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "conversation = '/WhatsApp Chat with Margi Pssc.txt'\n",
        "with open(conversation, encoding=\"utf-8\") as fp:\n",
        "    fp.readline()\n",
        "    messageBuffer = []\n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        line = fp.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        if date_time(line):\n",
        "            if len(messageBuffer) > 0:\n",
        "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "            messageBuffer.clear()\n",
        "            date, time, author, message = getDatapoint(line)\n",
        "            messageBuffer.append(message)\n",
        "        else:\n",
        "            messageBuffer.append(line)"
      ],
      "metadata": {
        "id": "9s8RrCMpwPy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=['Date', 'Time', 'Author', 'Message'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "print(df.tail(20))\n",
        "print(df.info())\n",
        "print(df.Author.unique())"
      ],
      "metadata": {
        "id": "KtOwu0jat9K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc169e37-a4a8-4bb9-c1fa-2f387057599f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Date, Time, Author, Message]\n",
            "Index: []\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 0 entries\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   Date     0 non-null      datetime64[ns]\n",
            " 1   Time     0 non-null      object        \n",
            " 2   Author   0 non-null      object        \n",
            " 3   Message  0 non-null      object        \n",
            "dtypes: datetime64[ns](1), object(3)\n",
            "memory usage: 0.0+ bytes\n",
            "None\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_messages = df.shape[0]\n",
        "print(total_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbe1YBgIuGIq",
        "outputId": "c2d2dc64-f53e-4618-fa4d-94114f230ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media_messages = df[df[\"Message\"]=='<Media omitted>'].shape[0]\n",
        "print(media_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfotAJw8uILa",
        "outputId": "c539160f-c6f6-4147-a584-49ae614c361a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_count(text):\n",
        "    emoji_list = []\n",
        "    data = regex.findall(r'\\X',text)\n",
        "    for word in data:\n",
        "        if any(char in emoji.EMOJI_DATA for char in word):\n",
        "            emoji_list.append(word)\n",
        "    return emoji_list\n",
        "df['emoji'] = df[\"Message\"].apply(split_count)\n",
        "\n",
        "emojis = sum(df['emoji'].str.len())\n",
        "print(emojis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HkK1KsWuI7W",
        "outputId": "5f9603b6-af5f-41df-e81f-4a060399f6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URLPATTERN = r'(https?://\\S+)'\n",
        "df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
        "links = np.sum(df.urlcount)\n",
        "\n",
        "print(\"Chats between Aman and Sapna\")\n",
        "print(\"Total Messages: \", total_messages)\n",
        "print(\"Number of Media Shared: \", media_messages)\n",
        "print(\"Number of Emojis Shared\", emojis)\n",
        "print(\"Number of Links Shared\", links)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd_2zG7OuMjx",
        "outputId": "47688ebf-b37e-4703-e360-43425d8f6f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chats between Aman and Sapna\n",
            "Total Messages:  0\n",
            "Number of Media Shared:  0\n",
            "Number of Emojis Shared 0\n",
            "Number of Links Shared 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
        "messages_df = df.drop(media_messages_df.index)\n",
        "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
        "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
        "messages_df[\"MessageCount\"]=1\n",
        "\n",
        "l = [\"Aman Kharwal\", \"Sapna\"]\n",
        "for i in range(len(l)):\n",
        "  # Filtering out messages of particular user\n",
        "  logsumexp= messages_df[messages_df[\"Author\"] == l[i]]\n",
        "  # req_df will contain messages of only one particular user\n",
        "  print(f'Stats of {l[i]} -')\n",
        "  # shape will print number of rows which indirectly means the number of messages\n",
        "  print('Messages Sent', logsumexp.shape[0])\n",
        "  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
        "  words_per_message = (np.sum(logsumexp['Word_Count']))/logsumexp.shape[0]\n",
        "  print('Average Words per message', words_per_message)\n",
        "  #media conists of media messages\n",
        "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
        "  print('Media Messages Sent', media)\n",
        "  # emojis conists of total emojis\n",
        "  emojis = sum(logsumexp['emoji'].str.len())\n",
        "  print('Emojis Sent', emojis)\n",
        "  #links consist of total links\n",
        "  links = sum(logsumexp[\"urlcount\"])\n",
        "  print('Links Sent', links)"
      ],
      "metadata": {
        "id": "DlcuUZeYuPfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "9e662e18-77bb-4b21-cce2-607a85726b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stats of Aman Kharwal -\n",
            "Messages Sent 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e4125a41fefa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Messages Sent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mwords_per_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word_Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Words per message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_per_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m#media conists of media messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))\n",
        "total_emojis = len(total_emojis_list)\n",
        "\n",
        "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
        "emoji_dict = dict(Counter(total_emojis_list))\n",
        "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "for i in emoji_dict:\n",
        "  print(i)\n",
        "\n",
        "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "import plotly.express as px\n",
        "fig = px.pie(emoji_df, values='count', names='emoji')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kyTnba-cuS7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(review for review in messages_df.Message)\n",
        "print (\"There are {} words in all the messages.\".format(len(text)))\n",
        "stopwords = set(STOPWORDS)\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "plt.figure( figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bQLndZ8ruYBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [\"Aman Kharwal\", \"Sapna\"]\n",
        "for i in range(len(l)):\n",
        "  dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
        "  text = \" \".join(review for review in dummy_df.Message)\n",
        "  stopwords = set(STOPWORDS)\n",
        "  #Generate a word cloud image\n",
        "  print('Author name',l[i])\n",
        "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "  #Display the generated image\n",
        "  plt.figure( figsize=(10,5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "apuLpzdMuc8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}